{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import wget \n",
    "from urllib.request import urlretrieve\n",
    "from  urllib.request import urlopen\n",
    "import urllib.error \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from enum import Enum, unique\n",
    "import inspect\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "from tensorflow.python.ops.variables import Variable\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('All modules imported.')\n",
    "\n",
    "source = 'https://d17h27t6h515a5.cloudfront.net/topher/2016/November/581faac4_traffic-signs-data/traffic-signs-data.zip'\n",
    "repository = 'traffic-signs-data.zip'\n",
    "batch_count = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/naaman/anaconda3/lib/python3.5/site-packages/pycuda/_driver.cpython-35m-x86_64-linux-gnu.so: undefined symbol: _ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEED1Ev",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0b81a819351f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoinit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSourceModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m '''\n",
      "\u001b[0;32m/home/naaman/anaconda3/lib/python3.5/site-packages/pycuda/driver.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_driver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"_v2\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/naaman/anaconda3/lib/python3.5/site-packages/pycuda/_driver.cpython-35m-x86_64-linux-gnu.so: undefined symbol: _ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEED1Ev"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy\n",
    "'''\n",
    "https://documen.tician.de/pycuda/tutorial.html\n",
    "Note that you do not have to use pycuda.autoinitâ€“ initialization, context creation, and cleanup \n",
    "can also be performed manually, if desired.\n",
    "'''\n",
    "\n",
    "\n",
    "a_gpu = gpuarray.to_gpu(numpy.random.randn(4,4).astype(numpy.float32))\n",
    "a_doubled = (2*a_gpu).get()\n",
    "print(a_doubled)\n",
    "print(a_gpu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self,source, repository):\n",
    "        \n",
    "        print('Status of Initialization Step #0')\n",
    "        if source is None:\n",
    "            print('None source parameter is not allowed. Please, provide a source parameter.')\n",
    "            return None\n",
    "        if len(source)==0:\n",
    "            print(\"Empty source parameter is not allowed. Please, provide a valid source parameter.\")\n",
    "            return None\n",
    "        if repository is None:\n",
    "            print('None repository parameter is not allowed. Please, provide a repository parameter.')\n",
    "            return None\n",
    "        if len(repository)==0:\n",
    "            print(\"Empty repository parameter is not allowed. Please, provide a valid repository parameter.\")\n",
    "            return None\n",
    "        \n",
    "        \n",
    "        self.__source = source\n",
    "        self.__repository=repository\n",
    "        self.__datacached,self.__dataloaded = False,False\n",
    "        self.__downloaded , self.__uncompressed = 0,0\n",
    "        self.train_size, self.test_size,self.class_size,self.label_per_class = 0,0,0,[]\n",
    "        self.image_shape = None\n",
    "        self.max_size_feature = (0,0)\n",
    "        \n",
    "    def __wget(self, source, repository):\n",
    "        try:\n",
    "            print(source)\n",
    "            content = urlopen(source)\n",
    "            repository = open(source.split('/')[-1], 'w')\n",
    "            repository.write(content.read())\n",
    "            content.close()\n",
    "            repository.close()\n",
    "        except Exception as err:\n",
    "            print('ERROR:', str(err))\n",
    "            raise \n",
    "        \n",
    "    \n",
    "    def __download(self):\n",
    "        print('Download Step #1')\n",
    "        #print(self.__source)\n",
    "        for src, rep in tqdm(zip(self.__source, self.__repository)):\n",
    "            try :\n",
    "                if not os.path.isfile(rep):\n",
    "                    print('Start download files from '+src+'...')\n",
    "                    urlretrieve(src,rep)\n",
    "                    #rep = wget.download(src)\n",
    "                    #self.__wget(src,rep)\n",
    "                    print('Download finished.')\n",
    "                    self.__downloaded += 1\n",
    "                else :\n",
    "                    print('Repository path '+rep+ ' is file! We can not save\\\n",
    "                            files because no directory path is provided.')\n",
    "            except urllib.error.URLError: #Exception as inst : #\n",
    "                    print('file not found corresponding to ' + src +'. moving on...')\n",
    "                    raise\n",
    "                    \n",
    "        if self.__downloaded != 0 :\n",
    "            print('Status of download Step : ' +str(self.__downloaded) + ' files are downloaded over '+\\\n",
    "                      str(len(self.__source)))\n",
    "            \n",
    "    def __uncompress(self):\n",
    "        print('Uncompression Step #3')\n",
    "        destfiles=[]\n",
    "        for path in self.__repository :\n",
    "        #Instantiate zipfile class as zipf context\n",
    "            #print(path)\n",
    "            with ZipFile(path,'r') as zipf:\n",
    "                #extracting file name list using progressbar\n",
    "                pbfiles = zipf.namelist()\n",
    "                for fname in tqdm(pbfiles, unit='files'):\n",
    "                    #check whether  file name do not point to a directory. Thus do not process it \n",
    "                    if not fname.endswith('/'):\n",
    "                        #unzip the image file using the file name\n",
    "                        print('Unzip the image file '+fname)\n",
    "                        #with zipf.open(fname) as file:\n",
    "                        zipf.extract(fname)\n",
    "\n",
    "                        # Now store the uncompressed data\n",
    "                        #fdest = fname[:-3]  # remove the '.gz' from the filename\n",
    "                        #print(fdest)\n",
    "                        destfiles.append(fname)\n",
    "                        \n",
    "            print('Status of uncompression Step :  '+ str(self.__uncompressed)+ \\\n",
    "                      'files are uncompressed over' +str(len(pbfiles)))\n",
    "        destfiles = sorted(destfiles,key=os.path.getsize, reverse=True)\n",
    "        return np.array(destfiles) \n",
    "    \n",
    "    def __load(self,pkfile):\n",
    "        # Reload the data\n",
    "        print('Data Loading Step #4')\n",
    "        train_features,train_labels = None,None\n",
    "        if os.path.isfile(pkfile):\n",
    "            #print(pkfile)\n",
    "            with open(pkfile, 'rb') as f:\n",
    "              pickle_data = pickle.load(f)\n",
    "              features = pickle_data['features']\n",
    "              labels = pickle_data['labels']\n",
    "              del pickle_data  # Free up memory\n",
    "            print('Status of Data loading from pickle file Step : successful')\n",
    "            self.__dataloaded = True\n",
    "        else :\n",
    "            print('Status of Data loading from pickle file Step : failed')\n",
    "        return features,labels\n",
    "    \n",
    "    def deserialize(self):\n",
    "        desfiles = []\n",
    "        print('The dataset deserialization process is starting...')\n",
    "        \n",
    "        if self.__downloaded==0:\n",
    "            self.__download()\n",
    "            \n",
    "        if self.__uncompressed == 0:\n",
    "            desfiles = self.__uncompress()\n",
    "            \n",
    "        if len(desfiles)==2 :\n",
    "            train_features, train_labels = self.__load(desfiles[0])\n",
    "            test_features,test_labels = self.__load(desfiles[1])\n",
    "            self.train_size = train_features.shape[0]\n",
    "            self.test_size = test_features.shape[0]\n",
    "            self.image_shape = (train_features.shape[1],train_features.shape[2],train_features.shape[3])\n",
    "            self.class_size = np.unique(train_labels).size\n",
    "            self.label_per_class = np.array([(k,len(list(v))) for k,v in groupby(y_train)])\n",
    "           \n",
    "            for t in self.label_per_class:\n",
    "                if(self.max_size_feature[1]<t[1]):\n",
    "                    self.max_size_feature = t\n",
    "            \n",
    "            \n",
    "        print('The dataset deserialization process is terminated...')\n",
    "        \n",
    "        return train_features,train_labels, test_features,test_labels\n",
    "    \n",
    "    def visualize(self, X_train, y_train) :\n",
    "        index = random.randint(0, len(X_train))\n",
    "        image = X_train[index].squeeze()\n",
    "\n",
    "        plt.figure(figsize=(1,1))\n",
    "        plt.imshow(image)\n",
    "        print(y_train[index])\n",
    "        \n",
    "    def __max(self, X_train, y_train, augmenter):\n",
    "        #Define the max(class,label/feature)\n",
    "        self.max_size_feature = (0,0)\n",
    "        for t in self.label_per_class:\n",
    "            if(self.max_size_feature[1]<t[1]):\n",
    "                self.max_size_feature = t\n",
    "    \n",
    "    def balance(self,X_train,y_train,augmenter,args):\n",
    "        #for each (class,feature/label) different from max, \n",
    "        # augment(class, feature/label) by the amount of tuple = max(class,feature) - nb(class,feature)\n",
    "        # Adjust(class, label)\n",
    "        # Append(Augmented(class,feature), train_feature)\n",
    "        #params = (1,1)\n",
    "        #print((augmenter) (*params))\n",
    "        augfeatures,auglabels =[],[]\n",
    "        start=0\n",
    "        for t in self.label_per_class:\n",
    "            augfeatures.append(X_train[t[1]])\n",
    "            auglabels.append(y_train[t[1]])\n",
    "            if t[1]!=self.max_size_feature[1]:\n",
    "                compensation = self.max_size_feature[1]-t[1]\n",
    "                print(compensation)\n",
    "                for i in range(compensation-1):\n",
    "                    bf = X_train[start:start+t[1]]\n",
    "                    bl = y_train[start:start+t[1]]\n",
    "                    args = (bf,args[1])\n",
    "                    ft = (augmenter)(*args)\n",
    "                    augfeatures.append(ft)\n",
    "                    auglabels.append(bl)\n",
    "                    start += t[1]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sources = [source]\n",
    "repositories = [repository]\n",
    "\n",
    "ds = Dataset(sources, repositories)\n",
    "X_train, y_train,X_test, y_test = ds.deserialize()\n",
    "print(\"Number of training examples =\", ds.train_size)\n",
    "print(\"Number of testing examples =\", ds.test_size)\n",
    "print(\"Image data shape =\", ds.image_shape)\n",
    "print(\"Number of classes =\", ds.class_size)\n",
    "#print(\"Number of label_per_class =\", ds.label_per_class)\n",
    "print(\"Max size of label_per_class =\", ds.max_size_feature)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ds.visualize(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1: Data Augmentation\n",
    "    This technique provides a way genrerate more data from the existing and thus makes cnn or dnn to be \n",
    "    trained on huge number of training dataset to reach better performance and accuracy.\n",
    "'''\n",
    "\n",
    "class DataAugmenter(object):\n",
    "    '''\n",
    "    This library class is a data augmenter pipeline manager using the Augmenters Module referenced at this url:\n",
    "    https://github.com/aleju/imgaug\n",
    "   '''\n",
    "    class Tasks(object):\n",
    "        def __str__(self):\n",
    "            return str(self.value)\n",
    "        \n",
    "        FlipVertical = 'flip_vertical'\n",
    "        FlipHorizontal = 'flip_horizontal'\n",
    "        Crop = 'crop'\n",
    "        GaussianBlur = 'gaussian_blur'\n",
    "        AdditiveGaussianNoise = 'additive_gaussian_noise'\n",
    "        Dropout = 'dropout'\n",
    "        Add = 'add'\n",
    "        Multiply = 'multiply'\n",
    "        ContrastNormalization = 'contrast_normalization'\n",
    "        Affine = 'afine'\n",
    "        ElasticTransformation = 'elastic_transformation'\n",
    "        \n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        # random example images\n",
    "        #images = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n",
    "\n",
    "        # Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "        # e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n",
    "        st = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "        self.pipeline = []\n",
    "        # Define our sequence of augmentation steps that will be applied to every image\n",
    "        # All augmenters with per_channel=0.5 will sample one value _per image_\n",
    "        # in 50% of all cases. In all other cases they will sample new values\n",
    "        # _per channel_.\n",
    "        self.tasks = []\n",
    "    \n",
    "    def flip_horizontal(self):\n",
    "        # horizontally flip 50% of all images\n",
    "        if not \"iaa.Fliplr\" in self.pipeline:\n",
    "            self.pipeline.append(iaa.Fliplr(0.5))\n",
    "            \n",
    "    def flip_vertical(self):\n",
    "        # vertically flip 50% of all images\n",
    "        if not \"iaa.Flipud\"  in self.pipeline:\n",
    "            self.pipeline.append(iaa.Flipud(0.5))\n",
    "            \n",
    "    def crop(self):\n",
    "        # crop images by crop range of 0-10%  of their height/width\n",
    "        if not \"iaa.Crop\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.Crop(percent=(0, 0.1))))\n",
    "    \n",
    "    def gaussian_blur(self):\n",
    "        # blur images with a sigma range between 0 and 3.0\n",
    "        if not \"iaa.GaussianBlur\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.GaussianBlur((0, 3.0))))\n",
    "    \n",
    "    def additive_gaussian_noise(self):\n",
    "        # add gaussian noise to images\n",
    "        if \"iaa.AdditiveGaussianNoise\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.2), per_channel=0.5)))\n",
    "    \n",
    "    def dropout(self):\n",
    "        # randomly remove up to 10% of the pixels  \n",
    "        if not \"iaa.Dropout\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.Dropout((0.0, 0.1), per_channel=0.5)))\n",
    "    \n",
    "    def add(self):\n",
    "        # change brightness of images (by -10 to 10 of original value)\n",
    "        if not \"iaa.Add\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.Add((-10, 10), per_channel=0.5)))\n",
    "    \n",
    "    def multiply(self):\n",
    "        # change brightness of images (50-150% of original value)\n",
    "        if not \"iaa.Multiply\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.Multiply((0.5, 1.5), per_channel=0.5)))\n",
    "        \n",
    "    def contrast_normalization(self):\n",
    "        # improve or worsen the contrast\n",
    "        if not \"iaa.ContrastNormalization\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5)))\n",
    "    \n",
    "    def affine(self):\n",
    "        \n",
    "        if not \"iaa.Affine\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.Affine(\n",
    "                    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "                    translate_px={\"x\": (-16, 16), \"y\": (-16, 16)}, # translate by -16 to +16 pixels (per axis)\n",
    "                    rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "                    shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "                    order=ia.ALL, # use any of scikit-image's interpolation methods\n",
    "                    cval=(0, 1.0), # if mode is constant, use a cval between 0 and 1.0\n",
    "                    mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "                )))\n",
    "            \n",
    "    def elastic_transformation(self):\n",
    "        # apply elastic transformations with random strengths\n",
    "        if not \"iaa.ElasticTransformation\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)))\n",
    "    \n",
    "        \n",
    "    def register(self,tasks):\n",
    "        #Allow to register the tailored data augmentation pipeline        \n",
    "        print('Augmenter Pipeline registration process is starting ...')\n",
    "        if tasks is None:\n",
    "            print('None tasks parameter is not allowed. Please, provide a tasks parameter.')\n",
    "            return None\n",
    "        if len(tasks)==0:\n",
    "            print(\"Empty tasks parameter is not allowed. Please, provide a valid tasks parameter.\")\n",
    "            return None\n",
    "        \n",
    "        self.tasks = tasks\n",
    "        \n",
    "        methnames = [m for m in dir(self) if inspect.ismethod(getattr(self, m))]                     \n",
    "\n",
    "        for taskname in tasks :                         \n",
    "            if taskname not in methnames:\n",
    "                print('The following method does not exists: ', taskname)\n",
    "                return\n",
    "        for taskname in tasks :\n",
    "            self.__getattribute__(taskname)()\n",
    "        \n",
    "        print('Augmenter Pipeline registration process is terminated ...')\n",
    "    \n",
    "    def execute(self, images, show=False):\n",
    "        print('Augmenter Pipeline execution process is starting ...')\n",
    "        pline = iaa.Sequential(self.pipeline, \n",
    "                             random_order = True # do all of the above in random order\n",
    "                                )                         \n",
    "        augmented_images = pline.augment_images(images)\n",
    "        \n",
    "        if show :\n",
    "            # show an image with 8*8 augmented versions of image 0\n",
    "            seq.show_grid(images[0], cols=8, rows=8)\n",
    "\n",
    "        print('Augmenter Pipeline execution process is terminated ...')\n",
    "        \n",
    "        return augmented_images\n",
    "\n",
    "def apply_augmentation2(batch_features, apply=False) :\n",
    "    \n",
    "    da = DataAugmenter()\n",
    "    \n",
    "    tasks = [da.Tasks.FlipHorizontal,da.Tasks.FlipVertical,da.Tasks.Crop,\n",
    "                da.Tasks.GaussianBlur,da.Tasks.Dropout,\n",
    "             da.Tasks.Affine,da.Tasks.ElasticTransformation]\n",
    "    \n",
    "    da.register(tasks)\n",
    "    \n",
    "    #batch_features, batch_labels  = load_batch(0,X_train, y_train)\n",
    "    \n",
    "    if apply :\n",
    "        images_aug = da.execute(batch_features)\n",
    "    else:\n",
    "        images_aug = batch_features\n",
    "        print('Not Apply')\n",
    "    #train_on_images(images_aug)\n",
    "    '''\n",
    "    for idx,image in enumerate(images_aug):\n",
    "        plt.figure(figsize=(1,1))\n",
    "        plt.imshow(image)\n",
    "        #print(batch_labels[idx])\n",
    "    '''\n",
    "    \n",
    "    print(len(images_aug))\n",
    "    \n",
    "    return images_aug\n",
    "\n",
    "def apply_augmentation(X_train, y_train, apply=False) :\n",
    "    \n",
    "    da = DataAugmenter()\n",
    "    \n",
    "    tasks = [da.Tasks.FlipHorizontal,da.Tasks.FlipVertical,da.Tasks.Crop,\n",
    "                da.Tasks.GaussianBlur,da.Tasks.Dropout,\n",
    "             da.Tasks.Affine,da.Tasks.ElasticTransformation]\n",
    "    \n",
    "    da.register(tasks)\n",
    "    \n",
    "    batch_features, batch_labels  = load_batch(0,X_train, y_train)\n",
    "    \n",
    "    if apply :\n",
    "        images_aug = da.execute(batch_features)\n",
    "    else:\n",
    "        images_aug = batch_features\n",
    "        print('Not Apply')\n",
    "    #train_on_images(images_aug)\n",
    "    \n",
    "    for idx,image in enumerate(images_aug):\n",
    "        plt.figure(figsize=(1,1))\n",
    "        plt.imshow(image)\n",
    "        print(batch_labels[idx])\n",
    "        \n",
    "def load_batch(batch_i,train_features,train_labels):\n",
    "    batch_size = 1000 #train_features/batch_count\n",
    "    # The training cycle\n",
    "    #for batch_i in range(batch_count):\n",
    "    # Get a batch of training features and labels\n",
    "    batch_start = batch_i*batch_size\n",
    "    batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "    batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "    return batch_features, batch_labels   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#apply_augmentation(X_train, y_train,True) \n",
    "args = (None,True)\n",
    "ds.balance(X_train,y_train,partial(apply_augmentation2),args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataPreProcessor(object):\n",
    "    '''\n",
    "    http://cs231n.github.io/neural-networks-2/#datapre\n",
    "    There are three common forms of data preprocessing a data matrix X, \n",
    "    where we will assume that X is of size [N x D] (N is the number of data, D is their dimensionality).\n",
    "    '''\n",
    "    \n",
    "    class Tasks(object):\n",
    "        SimpleRescale = '_simple_rescale'\n",
    "        MeanSubstract = '_mean_substract'\n",
    "        FeatureStandardization = '_feature_standardization'\n",
    "        \n",
    "    class Normalizer(object):\n",
    "        \n",
    "        def _simple_rescale(self,images):\n",
    "            images /= 255\n",
    "            return images\n",
    "        \n",
    "        def _mean_substract(self,images):\n",
    "            print('_zero_centred')\n",
    "            print(images.dtype)\n",
    "            #np.mean(images, axis = 0,dtype=np.uint8)\n",
    "            images -= np.mean(images, axis = 0,dtype=np.uint8)\n",
    "            return images\n",
    "        \n",
    "        def _feature_standardization(self, images):\n",
    "            print('_normalize')\n",
    "            images /= np.std(images, axis = 0)\n",
    "            return images\n",
    "        \n",
    "    class Sequential(object):\n",
    "        \n",
    "        def __init__(self, sequence):\n",
    "            self.sequence = sequence\n",
    "        \n",
    "        def preprocess_images(self,images):\n",
    "            obj = self.sequence[0]\n",
    "            self.sequence.remove(obj)\n",
    "            \n",
    "            for seq in self.sequence :\n",
    "                images = getattr(obj, seq)(images)\n",
    "                \n",
    "            return images\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pipeline = []\n",
    "        ppc = self.Normalizer()\n",
    "        self.pipeline.append(ppc)\n",
    "    \n",
    "    def simple_rescale(self):\n",
    "        if not \"_simple_rescale\" in  self.pipeline:\n",
    "            self.pipeline.append(\"_simple_rescale\") \n",
    "    \n",
    "    def mean_substract(self):\n",
    "        if not \"_mean_substract\" in  self.pipeline:\n",
    "            self.pipeline.append(\"_mean_substract\") \n",
    "        \n",
    "    def feature_standardization(self):\n",
    "        if \"_feature_standardization\" in  self.pipeline :\n",
    "            self.pipeline.append(\"_feature_standardization\") \n",
    "        \n",
    "    def register(self,tasks):\n",
    "        print('Preprocessor Pipeline registration process is starting ...')\n",
    "        if tasks is None:\n",
    "            print('None tasks parameter is not allowed. Please, provide a tasks parameter.')\n",
    "            return None\n",
    "        if len(tasks)==0:\n",
    "            print(\"Empty tasks parameter is not allowed. Please, provide a valid tasks parameter.\")\n",
    "            return None\n",
    "        \n",
    "        self.tasks = tasks\n",
    "        \n",
    "        methnames = [m for m in dir(self) if inspect.ismethod(getattr(self, m))]                     \n",
    "        print(methnames)\n",
    "        print(tasks)\n",
    "        for taskname in tasks :                         \n",
    "            if taskname not in methnames:\n",
    "                print('The following method does not exists: ', taskname)\n",
    "                return\n",
    "        for taskname in tasks :\n",
    "            self.__getattribute__(taskname)()\n",
    "        \n",
    "        print('Preprocessor Pipeline registration process is terminated ...')\n",
    "        \n",
    "    def execute(self, images, show=False):\n",
    "        print('Preprocessor Pipeline execution process is starting ...')\n",
    "        pline = self.Sequential(self.pipeline)\n",
    "        \n",
    "        imgs = pline.preprocess_images(images)\n",
    "        \n",
    "        if show :\n",
    "            # show an image with 8*8 augmented versions of image 0\n",
    "            seq.show_grid(imgs[0], cols=8, rows=8)\n",
    "\n",
    "        print('Preprocessor Pipeline execution process is terminated ...')\n",
    "        \n",
    "        return imgs\n",
    "    \n",
    "def apply_preprocessing(X_train, y_train, apply=False) :\n",
    "    dpp = DataPreProcessor()\n",
    "    pipeline = [dpp.Tasks.MeanSubstract,dpp.Tasks.FeatureStandardization]\n",
    "    dpp.register(pipeline)\n",
    "    \n",
    "    batch_features, batch_labels  = load_batch(0,X_train, y_train)\n",
    "    \n",
    "    if apply :\n",
    "        images_aug = dpp.execute(batch_features)\n",
    "    else:\n",
    "        images_aug = batch_features\n",
    "        print('Not Apply')\n",
    "    #train_on_images(images_aug)\n",
    "    \n",
    "    for idx,image in enumerate(images_aug):\n",
    "        plt.figure(figsize=(1,1))\n",
    "        plt.imshow(image)\n",
    "        print(batch_labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#apply_augmentation(X_train, y_train,False) \n",
    "#apply_preprocessing(X_train, y_train,True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
