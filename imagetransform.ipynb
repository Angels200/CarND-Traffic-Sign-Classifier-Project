{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from enum import Enum, unique\n",
    "print('All modules imported.')\n",
    "\n",
    "#@unique\n",
    "#class ParamTransform(Enum):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GeometricTransform(object):\n",
    "    #apply different geometric transformation to images like translation, rotation, affine transformation etc.\n",
    "    def __init__(self):\n",
    "        self.x = 0\n",
    "    \n",
    "    #Const\n",
    "    @constant\n",
    "    def INTER_CUBIC():\n",
    "        return cv2.INTER_CUBIC\n",
    "    \n",
    "    def shrink(self, img, f):\n",
    "        return self.__scale(img,f,cv2.INTER_AREA )\n",
    "    \n",
    "    def zoom(self,img,f):\n",
    "        return self.__scale(img,f,cv2.INTER_CUBIC)\n",
    "    \n",
    "    def __scale(self,img,f,interpolation):\n",
    "        img = cv2.imread(img,0)\n",
    "        height, width = img.shape[:2]\n",
    "        return cv2.resize(img,(f*width, f*height), interpolation = interpolation )\n",
    "    \n",
    "    def translate(self,img,shift):\n",
    "        img = cv2.imread(img,0)\n",
    "        rows,cols = img.shape\n",
    "        M = np.float32([[1,0,shift[0]],[0,1,shift[1]]])\n",
    "        return cv2.warpAffine(img,M,(cols,rows))\n",
    "    \n",
    "    def rotate(self, img, angle):\n",
    "        img = cv2.imread(img,0)\n",
    "        rows,cols = img.shape\n",
    "        M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
    "        return cv2.warpAffine(img,M,(cols,rows))\n",
    "    \n",
    "    \n",
    "    def affine_transform(self,img):\n",
    "        '''\n",
    "        In affine transformation, all parallel lines in the original image will still be parallel in the output \n",
    "        image. To find the transformation matrix,we need three points from input image and \n",
    "        their corresponding locations in output image\n",
    "        '''\n",
    "        img = cv2.imread(img)\n",
    "        rows,cols,ch = img.shape\n",
    "\n",
    "        pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "        pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    "        M = cv2.getAffineTransform(pts1,pts2)\n",
    "        return cv2.warpAffine(img,M,(cols,rows))\n",
    "        '''\n",
    "        plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "        plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "        plt.show()\n",
    "        '''\n",
    "    def perspective_transform(self,img):\n",
    "        '''\n",
    "        For perspective transformation, you need a 3x3 transformation matrix. Straight lines \n",
    "        will remain straight even after the transformation. To find this transformation matrix, you need \n",
    "        4 points on the input image and corresponding points on the output image. Among these 4 points, \n",
    "        3 of them should not be collinear.\n",
    "        '''\n",
    "        img = cv2.imread(img)\n",
    "        rows,cols,ch = img.shape\n",
    "        pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n",
    "        pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "        M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "        return cv2.warpPerspective(img,M,(300,300))\n",
    "        '''\n",
    "        plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "        plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "        plt.show()\n",
    "        '''\n",
    "    \n",
    "    def horizontal_flip(self, image):\n",
    "        return cv2.flip(image,0)\n",
    "    \n",
    "    def vertical_flip(self,image):\n",
    "        return cv2.flip(image,1)\n",
    "    \n",
    "    def random_crop(self, image):\n",
    "        '''\n",
    "        http://www.digicamhelp.com/processing-photos/basic-editing/why-crop-a-photo/\n",
    "        reasons to crop an image :\n",
    "        Improve overall composition\n",
    "        Focus on the main subject\n",
    "        Remove distracting elements from background or change the background by focusing on the subject\n",
    "        “Zoom in” on a subject:\n",
    "        Change the orientation of the image\n",
    "        '''\n",
    "    def __crop(self, image):\n",
    "        '''\n",
    "        http://northstar-www.dartmouth.edu/doc/idl/html_6.2/Cropping_Images.html\n",
    "        Cropping an image extracts a rectangular region of interest from the original image. \n",
    "        This focuses the viewer's attention on a specific portion of the image and discards areas of \n",
    "        the image that contain less useful information. Using image cropping in conjunction with image \n",
    "        magnification allows you to zoom in on a specific portion of the image. This section describes \n",
    "        how to exactly define the portion of the image you wish to extract to create a cropped imag\n",
    "        '''\n",
    "        \n",
    "        return img[x0:x0+224, y0:y0+224] \n",
    "        \n",
    "class ColorSpace(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        x=0\n",
    "    \n",
    "    def rgbtohsv(self,image):\n",
    "        return __change(image,cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    def rgbtoycrcb(self,image):\n",
    "        return __change(image,cv2.COLOR_RGB2YCrCb)\n",
    "    \n",
    "    def rgbtogray(self,image):\n",
    "        return __change(image,cv2.COLOR_RGBA2GRAY)\n",
    "         \n",
    "\n",
    "    def rgbtoyuv(self, image)\n",
    "        return __change(image,cv2.COLOR_RGB2H)\n",
    "        \n",
    "    def __change(self,image,target):\n",
    "        return cv2.cvtColor(image, target)\n",
    "        \n",
    "    \n",
    "    def color_selection(self,image,low,high):\n",
    "        hsv=cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        mask = cv2.inRange(hsv, low, high) \n",
    "        return cv2.bitwise_and(image,image, mask= mask)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
