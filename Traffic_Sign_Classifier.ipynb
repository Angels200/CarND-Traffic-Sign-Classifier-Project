{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = 'train.p'\n",
    "testing_file = 'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 2D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**\n",
    "\n",
    "Complete the basic data summary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Replace each question mark with the appropriate value.\n",
    "import numpy as np\n",
    "# TODO: Number of training examples\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = (X_train.shape[1],X_train.shape[2],X_train.shape[3])\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = np.unique(y_train).size\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the German Traffic Signs Dataset using the pickled file(s). This is open ended, suggestions include: plotting traffic sign images, plotting the count of each sign, etc.\n",
    "\n",
    "The [Matplotlib](http://matplotlib.org/) [examples](http://matplotlib.org/examples/index.html) and [gallery](http://matplotlib.org/gallery.html) pages are a great resource for doing visualizations in Python.\n",
    "\n",
    "**NOTE:** It's recommended you start with something simple first. If you wish to do more, come back to it after you've completed the rest of the sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Data exploration visualization goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize(X_train, y_train) :\n",
    "        index = random.randint(0, len(X_train))\n",
    "        image = X_train[index].squeeze()\n",
    "\n",
    "        plt.figure(figsize=(1,1))\n",
    "        plt.imshow(image)\n",
    "        print('Label : ',y_train[index])\n",
    "        \n",
    "visualize(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library member 'class Dataset' return a Dataset of features and labels by taking as input an url and the name of the repository. It offers the following features :\n",
    "    1.download : download the zip file from an url\n",
    "    2.uncompress : uncommpres the zip file and extract the pickle file to a given repository\n",
    "    3.load : load the dataset from the pickle file in memory\n",
    "    4.visualize : show randomly feature and label\n",
    "    5.give statistics on dataset : \n",
    "                5.1.the number of lable or feature per class\n",
    "                5.2.the number of the class in the dataset\n",
    "                5.3.the shape of the feature and label\n",
    "                5.4.the class which has the max number of label and feature (useful when augmenting the dataset)\n",
    "    6.balance : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import wget \n",
    "from urllib.request import urlretrieve\n",
    "from  urllib.request import urlopen\n",
    "import urllib.error \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imgaug as ia\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "from tensorflow.python.ops.variables import Variable\n",
    "from itertools import groupby\n",
    "from imgaug import augmenters as iaa\n",
    "from enum import Enum, unique\n",
    "import inspect\n",
    "%matplotlib inline\n",
    "\n",
    "print('All modules imported.')\n",
    "\n",
    "source = 'https://d17h27t6h515a5.cloudfront.net/topher/2016/November/581faac4_traffic-signs-data/traffic-signs-data.zip'\n",
    "repository = 'traffic-signs-data.zip'\n",
    "batch_count = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self,source, repository):\n",
    "        \n",
    "        print('Status of Initialization Step #0')\n",
    "        if source is None:\n",
    "            print('None source parameter is not allowed. Please, provide a source parameter.')\n",
    "            return None\n",
    "        if len(source)==0:\n",
    "            print(\"Empty source parameter is not allowed. Please, provide a valid source parameter.\")\n",
    "            return None\n",
    "        if repository is None:\n",
    "            print('None repository parameter is not allowed. Please, provide a repository parameter.')\n",
    "            return None\n",
    "        if len(repository)==0:\n",
    "            print(\"Empty repository parameter is not allowed. Please, provide a valid repository parameter.\")\n",
    "            return None\n",
    "        \n",
    "        \n",
    "        self.__source = source\n",
    "        self.__repository=repository\n",
    "        self.__datacached,self.__dataloaded = False,False\n",
    "        self.__downloaded , self.__uncompressed = 0,0\n",
    "        self.train_size, self.test_size,self.class_size,self.label_per_class = 0,0,0,[]\n",
    "        self.image_shape = None\n",
    "        self.max_size_feature = None\n",
    "        \n",
    "    def __wget(self, source, repository):\n",
    "        try:\n",
    "            print(source)\n",
    "            content = urlopen(source)\n",
    "            repository = open(source.split('/')[-1], 'w')\n",
    "            repository.write(content.read())\n",
    "            content.close()\n",
    "            repository.close()\n",
    "        except Exception as err:\n",
    "            print('ERROR:', str(err))\n",
    "            raise \n",
    "        \n",
    "    \n",
    "    def __download(self):\n",
    "        print('Download Step #1')\n",
    "        #print(self.__source)\n",
    "        for src, rep in tqdm(zip(self.__source, self.__repository)):\n",
    "            try :\n",
    "                if not os.path.isfile(rep):\n",
    "                    print('Start download files from '+src+'...')\n",
    "                    urlretrieve(src,rep)\n",
    "                    #rep = wget.download(src)\n",
    "                    #self.__wget(src,rep)\n",
    "                    print('Download finished.')\n",
    "                    self.__downloaded += 1\n",
    "                else :\n",
    "                    print('Repository path '+rep+ ' is file! We can not save\\\n",
    "                            files because no directory path is provided.')\n",
    "            except urllib.error.URLError: #Exception as inst : #\n",
    "                    print('file not found corresponding to ' + src +'. moving on...')\n",
    "                    raise\n",
    "                    \n",
    "        if self.__downloaded != 0 :\n",
    "            print('Status of download Step : ' +str(self.__downloaded) + ' files are downloaded over '+\\\n",
    "                      str(len(self.__source)))\n",
    "            \n",
    "    def __uncompress(self):\n",
    "        print('Uncompression Step #3')\n",
    "        destfiles=[]\n",
    "        for path in self.__repository :\n",
    "        #Instantiate zipfile class as zipf context\n",
    "            #print(path)\n",
    "            with ZipFile(path,'r') as zipf:\n",
    "                #extracting file name list using progressbar\n",
    "                pbfiles = zipf.namelist()\n",
    "                for fname in tqdm(pbfiles, unit='files'):\n",
    "                    #check whether  file name do not point to a directory. Thus do not process it \n",
    "                    if not fname.endswith('/'):\n",
    "                        #unzip the image file using the file name\n",
    "                        print('Unzip the image file '+fname)\n",
    "                        #with zipf.open(fname) as file:\n",
    "                        zipf.extract(fname)\n",
    "\n",
    "                        # Now store the uncompressed data\n",
    "                        #fdest = fname[:-3]  # remove the '.gz' from the filename\n",
    "                        #print(fdest)\n",
    "                        destfiles.append(fname)\n",
    "                        \n",
    "            print('Status of uncompression Step :  '+ str(self.__uncompressed)+ \\\n",
    "                      'files are uncompressed over' +str(len(pbfiles)))\n",
    "        destfiles = sorted(destfiles,key=os.path.getsize, reverse=True)\n",
    "        return np.array(destfiles) \n",
    "    \n",
    "    def __load(self,pkfile):\n",
    "        # Reload the data\n",
    "        print('Data Loading Step #4')\n",
    "        train_features,train_labels = None,None\n",
    "        if os.path.isfile(pkfile):\n",
    "            #print(pkfile)\n",
    "            with open(pkfile, 'rb') as f:\n",
    "              pickle_data = pickle.load(f)\n",
    "              features = pickle_data['features']\n",
    "              labels = pickle_data['labels']\n",
    "              del pickle_data  # Free up memory\n",
    "            print('Status of Data loading from pickle file Step : successful')\n",
    "            self.__dataloaded = True\n",
    "        else :\n",
    "            print('Status of Data loading from pickle file Step : failed')\n",
    "        return features,labels\n",
    "    \n",
    "    def deserialize(self):\n",
    "        desfiles = []\n",
    "        print('The dataset deserialization process is starting...')\n",
    "        \n",
    "        if self.__downloaded==0:\n",
    "            self.__download()\n",
    "            \n",
    "        if self.__uncompressed == 0:\n",
    "            desfiles = self.__uncompress()\n",
    "            \n",
    "        if len(desfiles)==2 :\n",
    "            train_features, train_labels = self.__load(desfiles[0])\n",
    "            test_features,test_labels = self.__load(desfiles[1])\n",
    "            self.train_size = train_features.shape[0]\n",
    "            self.test_size = test_features.shape[0]\n",
    "            self.image_shape = (train_features.shape[1],train_features.shape[2],train_features.shape[3])\n",
    "            self.class_size = np.unique(train_labels).size\n",
    "            self.label_per_class = np.array([(k,len(list(v))) for k,v in groupby(y_train)])\n",
    "            self.max_size_feature = max(max(self.label_per_class))\n",
    "        print('The dataset deserialization process is terminated...')\n",
    "        \n",
    "        return train_features,train_labels, test_features,test_labels\n",
    "    \n",
    "    def visualize(self, X_train, y_train) :\n",
    "        index = random.randint(0, len(X_train))\n",
    "        image = X_train[index].squeeze()\n",
    "\n",
    "        plt.figure(figsize=(1,1))\n",
    "        plt.imshow(image)\n",
    "        print(y_train[index])\n",
    "        \n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sources = [source]\n",
    "repositories = [repository]\n",
    "\n",
    "ds = Dataset(sources, repositories)\n",
    "X_train, y_train,X_test, y_test = ds.deserialize()\n",
    "print(\"Number of training examples =\", ds.train_size)\n",
    "print(\"Number of testing examples =\", ds.test_size)\n",
    "print(\"Image data shape =\", ds.image_shape)\n",
    "print(\"Number of classes =\", ds.class_size)\n",
    "print(\"Number of label_per_class =\", ds.label_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these.\n",
    "\n",
    "**NOTE:** The LeNet-5 implementation shown in the [classroom](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) at the end of the CNN lesson is a solid starting point. You'll have to change the number of classes and possibly the preprocessing, but aside from that it's plug and play!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1: Data Augmentation\n",
    "    This technique provides a way genrerate more data from the existing and thus makes cnn or dnn to be \n",
    "    trained on huge number of training dataset to reach better performance and accuracy.\n",
    "'''\n",
    "\n",
    "class DataAugmenter(object):\n",
    "    '''\n",
    "    This library class is a data augmenter pipeline manager using the Augmenters Module referenced at this url:\n",
    "    https://github.com/aleju/imgaug\n",
    "   '''\n",
    "    class Tasks(object):\n",
    "        def __str__(self):\n",
    "            return str(self.value)\n",
    "        \n",
    "        FlipVertical = 'flip_vertical'\n",
    "        FlipHorizontal = 'flip_horizontal'\n",
    "        Crop = 'crop'\n",
    "        GaussianBlur = 'gaussian_blur'\n",
    "        AdditiveGaussianNoise = 'additive_gaussian_noise'\n",
    "        Dropout = 'dropout'\n",
    "        Add = 'add'\n",
    "        Multiply = 'multiply'\n",
    "        ContrastNormalization = 'contrast_normalization'\n",
    "        Affine = 'afine'\n",
    "        ElasticTransformation = 'elastic_transformation'\n",
    "        \n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        # random example images\n",
    "        #images = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n",
    "\n",
    "        # Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "        # e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n",
    "        st = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "        self.pipeline = []\n",
    "        # Define our sequence of augmentation steps that will be applied to every image\n",
    "        # All augmenters with per_channel=0.5 will sample one value _per image_\n",
    "        # in 50% of all cases. In all other cases they will sample new values\n",
    "        # _per channel_.\n",
    "        self.tasks = []\n",
    "    \n",
    "    def flip_horizontal(self):\n",
    "        # horizontally flip 50% of all images\n",
    "        if not \"iaa.Fliplr\" in self.pipeline:\n",
    "            self.pipeline.append(iaa.Fliplr(0.5))\n",
    "            \n",
    "    def flip_vertical(self):\n",
    "        # vertically flip 50% of all images\n",
    "        if not \"iaa.Flipud\"  in self.pipeline:\n",
    "            self.pipeline.append(iaa.Flipud(0.5))\n",
    "            \n",
    "    def crop(self):\n",
    "        # crop images by crop range of 0-10%  of their height/width\n",
    "        if not \"iaa.Crop\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.Crop(percent=(0, 0.1))))\n",
    "    \n",
    "    def gaussian_blur(self):\n",
    "        # blur images with a sigma range between 0 and 3.0\n",
    "        if not \"iaa.GaussianBlur\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.GaussianBlur((0, 3.0))))\n",
    "    \n",
    "    def additive_gaussian_noise(self):\n",
    "        # add gaussian noise to images\n",
    "        if \"iaa.AdditiveGaussianNoise\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.2), per_channel=0.5)))\n",
    "    \n",
    "    def dropout(self):\n",
    "        # randomly remove up to 10% of the pixels  \n",
    "        if not \"iaa.Dropout\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.Dropout((0.0, 0.1), per_channel=0.5)))\n",
    "    \n",
    "    def add(self):\n",
    "        # change brightness of images (by -10 to 10 of original value)\n",
    "        if not \"iaa.Add\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.Add((-10, 10), per_channel=0.5)))\n",
    "    \n",
    "    def multiply(self):\n",
    "        # change brightness of images (50-150% of original value)\n",
    "        if not \"iaa.Multiply\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.Multiply((0.5, 1.5), per_channel=0.5)))\n",
    "        \n",
    "    def contrast_normalization(self):\n",
    "        # improve or worsen the contrast\n",
    "        if not \"iaa.ContrastNormalization\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5)))\n",
    "    \n",
    "    def affine(self):\n",
    "        \n",
    "        if not \"iaa.Affine\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.Affine(\n",
    "                    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "                    translate_px={\"x\": (-16, 16), \"y\": (-16, 16)}, # translate by -16 to +16 pixels (per axis)\n",
    "                    rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "                    shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "                    order=ia.ALL, # use any of scikit-image's interpolation methods\n",
    "                    cval=(0, 1.0), # if mode is constant, use a cval between 0 and 1.0\n",
    "                    mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "                )))\n",
    "            \n",
    "    def elastic_transformation(self):\n",
    "        # apply elastic transformations with random strengths\n",
    "        if not \"iaa.ElasticTransformation\" in self.pipeline:\n",
    "            self.pipeline.append(st(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)))\n",
    "    \n",
    "        \n",
    "    def register(self,tasks):\n",
    "        #Allow to register the tailored data augmentation pipeline        \n",
    "        print('Augmenter Pipeline registration process is starting ...')\n",
    "        if tasks is None:\n",
    "            print('None tasks parameter is not allowed. Please, provide a tasks parameter.')\n",
    "            return None\n",
    "        if len(tasks)==0:\n",
    "            print(\"Empty tasks parameter is not allowed. Please, provide a valid tasks parameter.\")\n",
    "            return None\n",
    "        \n",
    "        self.tasks = tasks\n",
    "        \n",
    "        methnames = [m for m in dir(self) if inspect.ismethod(getattr(self, m))]                     \n",
    "\n",
    "        for taskname in tasks :                         \n",
    "            if taskname not in methnames:\n",
    "                print('The following method does not exists: ', taskname)\n",
    "                return\n",
    "        for taskname in tasks :\n",
    "            self.__getattribute__(taskname)()\n",
    "        \n",
    "        print('Augmenter Pipeline registration process is terminated ...')\n",
    "    \n",
    "    def execute(self, images, show=False):\n",
    "        print('Augmenter Pipeline execution process is starting ...')\n",
    "        pline = iaa.Sequential(self.pipeline, \n",
    "                             random_order = True # do all of the above in random order\n",
    "                                )                         \n",
    "        augmented_images = pline.augment_images(images)\n",
    "        \n",
    "        if show :\n",
    "            # show an image with 8*8 augmented versions of image 0\n",
    "            seq.show_grid(images[0], cols=8, rows=8)\n",
    "\n",
    "        print('Augmenter Pipeline execution process is terminated ...')\n",
    "        \n",
    "        return augmented_images\n",
    "\n",
    "\n",
    "\n",
    "def apply_augmentation(X_train, y_train, apply=False) :\n",
    "    \n",
    "    da = DataAugmenter()\n",
    "    \n",
    "    tasks = [da.Tasks.FlipHorizontal,da.Tasks.FlipVertical,da.Tasks.Crop,\n",
    "                da.Tasks.GaussianBlur,da.Tasks.Dropout,\n",
    "             da.Tasks.Affine,da.Tasks.ElasticTransformation]\n",
    "    \n",
    "    da.register(tasks)\n",
    "    \n",
    "    batch_features, batch_labels  = load_batch(0,X_train, y_train)\n",
    "    \n",
    "    if apply :\n",
    "        images_aug = da.execute(batch_features)\n",
    "    else:\n",
    "        images_aug = batch_features\n",
    "        print('Not Apply')\n",
    "    #train_on_images(images_aug)\n",
    "    \n",
    "    for idx,image in enumerate(images_aug):\n",
    "        plt.figure(figsize=(1,1))\n",
    "        plt.imshow(image)\n",
    "        print(batch_labels[idx])\n",
    "        \n",
    "def load_batch(batch_i,train_features,train_labels):\n",
    "    batch_size = 1000 #train_features/batch_count\n",
    "    # The training cycle\n",
    "    #for batch_i in range(batch_count):\n",
    "    # Get a batch of training features and labels\n",
    "    batch_start = batch_i*batch_size\n",
    "    batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "    batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "    return batch_features, batch_labels   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "\n",
    "_Describe how you preprocessed the data. Why did you choose that technique?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "The preprocess stage aims to :\n",
    "    1.Split the train dataset into train dataset and validation datase.\n",
    "    2.Normalize data\n",
    "\n",
    "1.Split the train dataset into train dataset and validation dataset. If the number of input data is insuffisiant we can add more data using the Data augmentation process. For the purpose of this project, i propose to generate more data for the train and test datasets using the data augmenter and split randomly the augmented train dataset into a new train dataset and a validation dataset.\n",
    "\n",
    "\n",
    "2.Data Normalization : in order to make the learning process performing better. The CNN learns its weights by adding gradient error vectors multiplied by the learning rate computed from backprop to weight matrices as the training process is running. so we end up with the following equation :\n",
    "W = W + (learningrate * gradient descent)\n",
    "\n",
    "Initial conditions : At the begining of the learning process, the input features values distributions are different for each one (feature). Thus the learning rate would correct in each dimension from one another. it might be over compensating a correction in one weight dimension while undercompensating in another.\n",
    "\n",
    "The gradient descent find itself oscillating and unable to center or moving slowly  onto a better minima. So therefore, to reach a better minima and avoiding the oscillation (see above)  we need to normalize the input features values.\n",
    "\n",
    "The scenario for preprocessing dataset is based on dataset normalization using three following methods to compare the average error (%) for each (http://ijssst.info/Vol-15/No-2/data/3251a024.pdf §IV. RESULTS AND DISCUSSIONS.)\n",
    "\n",
    "The methods are :\n",
    "    1.Simple Rescale\n",
    "    2.Substract Mean \n",
    "    3.Feature Standardization\n",
    "\n",
    "\n",
    "Each normalization methods is implemented by a \"normalized\" pipeline (see \"class DataPreProcessor\" bellow).\n",
    "The normalization is part of the preprocess stage and should be applied after the Data augmentation stage (see later \"class DataAugmenter\") if exists.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Generate data additional data (OPTIONAL!)\n",
    "### and split the data into training/validation/testing sets here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import wget \n",
    "import inspect\n",
    "from urllib.request import urlretrieve\n",
    "from  urllib.request import urlopen\n",
    "import urllib.error \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "from tensorflow.python.ops.variables import Variable\n",
    "%matplotlib inline\n",
    "\n",
    "print('All modules imported.')\n",
    "\n",
    "### Preprocess the data here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "class DataPreProcessor(object):\n",
    "    '''\n",
    "    http://cs231n.github.io/neural-networks-2/#datapre\n",
    "    There are three common forms of data preprocessing a data matrix X, \n",
    "    where we will assume that X is of size [N x D] (N is the number of data, D is their dimensionality).\n",
    "    '''\n",
    "    \n",
    "    class Tasks(object):\n",
    "        SimpleRescale = '_simple_rescale'\n",
    "        MeanSubstract = '_mean_substract'\n",
    "        FeatureStandardization = '_feature_standardization'\n",
    "        \n",
    "    class Normalizer(object):\n",
    "        \n",
    "        def _simple_rescale(self,images):\n",
    "            images /= 255\n",
    "            return images\n",
    "        \n",
    "        def _mean_substract(self,images):\n",
    "            print('_zero_centred')\n",
    "            print(images.dtype)\n",
    "            #np.mean(images, axis = 0,dtype=np.uint8)\n",
    "            images -= np.mean(images, axis = 0,dtype=np.uint8)\n",
    "            return images\n",
    "        \n",
    "        def _feature_standardization(self, images):\n",
    "            print('_normalize')\n",
    "            images /= np.std(images, axis = 0)\n",
    "            return images\n",
    "        \n",
    "    class Sequential(object):\n",
    "        \n",
    "        def __init__(self, sequence):\n",
    "            self.sequence = sequence\n",
    "        \n",
    "        def preprocess_images(self,images):\n",
    "            obj = self.sequence[0]\n",
    "            self.sequence.remove(obj)\n",
    "            \n",
    "            for seq in self.sequence :\n",
    "                images = getattr(obj, seq)(images)\n",
    "                \n",
    "            return images\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pipeline = []\n",
    "        ppc = self.Normalizer()\n",
    "        self.pipeline.append(ppc)\n",
    "    \n",
    "    def simple_rescale(self):\n",
    "        if not \"_simple_rescale\" in  self.pipeline:\n",
    "            self.pipeline.append(\"_simple_rescale\") \n",
    "    \n",
    "    def mean_substract(self):\n",
    "        if not \"_mean_substract\" in  self.pipeline:\n",
    "            self.pipeline.append(\"_mean_substract\") \n",
    "        \n",
    "    def feature_standardization(self):\n",
    "        if \"_feature_standardization\" in  self.pipeline :\n",
    "            self.pipeline.append(\"_feature_standardization\") \n",
    "        \n",
    "    def register(self,tasks):\n",
    "        print('Preprocessor Pipeline registration process is starting ...')\n",
    "        if tasks is None:\n",
    "            print('None tasks parameter is not allowed. Please, provide a tasks parameter.')\n",
    "            return None\n",
    "        if len(tasks)==0:\n",
    "            print(\"Empty tasks parameter is not allowed. Please, provide a valid tasks parameter.\")\n",
    "            return None\n",
    "        \n",
    "        self.tasks = tasks\n",
    "        \n",
    "        methnames = [m for m in dir(self) if inspect.ismethod(getattr(self, m))]                     \n",
    "        print(methnames)\n",
    "        print(tasks)\n",
    "        for taskname in tasks :                         \n",
    "            if taskname not in methnames:\n",
    "                print('The following method does not exists: ', taskname)\n",
    "                return\n",
    "        for taskname in tasks :\n",
    "            self.__getattribute__(taskname)()\n",
    "        \n",
    "        print('Preprocessor Pipeline registration process is terminated ...')\n",
    "        \n",
    "    def execute(self, images, show=False):\n",
    "        print('Preprocessor Pipeline execution process is starting ...')\n",
    "        pline = self.Sequential(self.pipeline)\n",
    "        \n",
    "        imgs = pline.preprocess_images(images)\n",
    "        \n",
    "        if show :\n",
    "            # show an image with 8*8 augmented versions of image 0\n",
    "            seq.show_grid(imgs[0], cols=8, rows=8)\n",
    "\n",
    "        print('Preprocessor Pipeline execution process is terminated ...')\n",
    "        \n",
    "        return imgs\n",
    "\n",
    "def apply_preprocessing(X_train, y_train, apply=False) :\n",
    "    '''\n",
    "    This method apply the normalization pipleline composed of Mean Substract and Feature standardization ==>\n",
    "    two dimensions Zero centred data\n",
    "    The normalization is applied on a batch of dataset.\n",
    "    '''\n",
    "    dpp = DataPreProcessor()\n",
    "    pipeline = [dpp.Tasks.MeanSubstract,dpp.Tasks.FeatureStandardization]\n",
    "    dpp.register(pipeline)\n",
    "    \n",
    "    batch_features, batch_labels  = load_batch(0,X_train, y_train)\n",
    "    \n",
    "    if apply :\n",
    "        images_aug = dpp.execute(batch_features)\n",
    "    else:\n",
    "        images_aug = batch_features\n",
    "        print('Not Apply')\n",
    "    #train_on_images(images_aug)\n",
    "    \n",
    "    for idx,image in enumerate(images_aug):\n",
    "        plt.figure(figsize=(1,1))\n",
    "        plt.imshow(image)\n",
    "        print(batch_labels[idx])\n",
    "        \n",
    "def load_batch(batch_i,train_features,train_labels):\n",
    "    batch_size = 1000 #train_features/batch_count\n",
    "    # The training cycle\n",
    "    #for batch_i in range(batch_count):\n",
    "    # Get a batch of training features and labels\n",
    "    batch_start = batch_i*batch_size\n",
    "    batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "    batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "    return batch_features, batch_labels   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apply_preprocessing(X_train, y_train,True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "_Describe how you set up the training, validation and testing data for your model. **Optional**: If you generated additional data, how did you generate the data? Why did you generate the data? What are the differences in the new dataset (with generated data) from the original dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)  For reference on how to build a deep neural network using TensorFlow, see [Deep Neural Network in TensorFlow\n",
    "](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/b516a270-8600-4f93-a0a3-20dfeabe5da6/concepts/83a3a2a2-a9bd-4b7b-95b0-eb924ab14432) from the classroom._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "_How did you train your model? (Type of optimizer, batch size, epochs, hyperparameters, etc.)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "\n",
    "_What approach did you take in coming up with a solution to this problem? It may have been a process of trial and error, in which case, outline the steps you took to get to the final solution and why you chose those steps. Perhaps your solution involved an already well known implementation or architecture. In this case, discuss why you think this is suitable for the current problem._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "Take several pictures of traffic signs that you find on the web or around you (at least five), and run them through your classifier on your computer to produce example results. The classifier might not recognize some local signs but it could prove interesting nonetheless.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "_Choose five candidate images of traffic signs and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult? It could be helpful to plot the images in the notebook._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Run the predictions here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "_Is your model able to perform equally well on captured pictures when compared to testing on the dataset? The simplest way to do this check the accuracy of the predictions. For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate._\n",
    "\n",
    "_**NOTE:** You could check the accuracy manually by using `signnames.csv` (same directory). This file has a mapping from the class id (0-42) to the corresponding sign name. So, you could take the class id the model outputs, lookup the name in `signnames.csv` and see if it matches the sign from the image._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Visualize the softmax probabilities here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "*Use the model's softmax probabilities to visualize the **certainty** of its predictions, [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#top_k) could prove helpful here. Which predictions is the model certain of? Uncertain? If the model was incorrect in its initial prediction, does the correct prediction appear in the top k? (k should be 5 at most)*\n",
    "\n",
    "`tf.nn.top_k` will return the values and indices (class ids) of the top k predictions. So if k=3, for each sign, it'll return the 3 largest probabilities (out of a possible 43) and the correspoding class ids.\n",
    "\n",
    "Take this numpy array as an example:\n",
    "\n",
    "```\n",
    "# (5, 6) array\n",
    "a = np.array([[ 0.24879643,  0.07032244,  0.12641572,  0.34763842,  0.07893497,\n",
    "         0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.08594638,  0.0178669 ,  0.18063401,\n",
    "         0.15899337],\n",
    "       [ 0.26076848,  0.23664738,  0.08020603,  0.07001922,  0.1134371 ,\n",
    "         0.23892179],\n",
    "       [ 0.11943333,  0.29198961,  0.02605103,  0.26234032,  0.1351348 ,\n",
    "         0.16505091],\n",
    "       [ 0.09561176,  0.34396535,  0.0643941 ,  0.16240774,  0.24206137,\n",
    "         0.09155967]])\n",
    "```\n",
    "\n",
    "Running it through `sess.run(tf.nn.top_k(tf.constant(a), k=3))` produces:\n",
    "\n",
    "```\n",
    "TopKV2(values=array([[ 0.34763842,  0.24879643,  0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.18063401],\n",
    "       [ 0.26076848,  0.23892179,  0.23664738],\n",
    "       [ 0.29198961,  0.26234032,  0.16505091],\n",
    "       [ 0.34396535,  0.24206137,  0.16240774]]), indices=array([[3, 0, 5],\n",
    "       [0, 1, 4],\n",
    "       [0, 5, 1],\n",
    "       [1, 3, 5],\n",
    "       [1, 4, 3]], dtype=int32))\n",
    "```\n",
    "\n",
    "Looking just at the first row we get `[ 0.34763842,  0.24879643,  0.12789202]`, you can confirm these are the 3 largest probabilities in `a`. You'll also notice `[3, 0, 5]` are the corresponding indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
